# Memory Operations Guide - ACS-Mentor V2.1
# å†…å­˜ç³»ç»Ÿæ“ä½œæŒ‡å—

**ç‰ˆæœ¬**: V2.1
**åˆ›å»ºæ—¥æœŸ**: 2025-11-16
**é€‚ç”¨äº**: ACS-Mentorç³»ç»Ÿé›†æˆmemory_system.yaml

---

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [ç³»ç»Ÿåˆå§‹åŒ–](#ç³»ç»Ÿåˆå§‹åŒ–)
3. [æ ¸å¿ƒæ“ä½œæµç¨‹](#æ ¸å¿ƒæ“ä½œæµç¨‹)
4. [Pre-Guidanceå†…å­˜å¢å¼º](#pre-guidanceå†…å­˜å¢å¼º)
5. [Post-Guidanceå­¦ä¹ æå–](#post-guidanceå­¦ä¹ æå–)
6. [é”™è¯¯æ¨¡å¼æ£€æµ‹](#é”™è¯¯æ¨¡å¼æ£€æµ‹)
7. [ç”¨æˆ·èƒ½åŠ›è¿½è¸ª](#ç”¨æˆ·èƒ½åŠ›è¿½è¸ª)
8. [é™çº§ä¸å®¹é”™](#é™çº§ä¸å®¹é”™)
9. [å®ç°å‚è€ƒ](#å®ç°å‚è€ƒ)

---

## æ¦‚è¿°

### å†…å­˜ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI Agent (ACS-Mentor Decision Logic)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Operations Layer (æœ¬æŒ‡å—)                      â”‚
â”‚  â”œâ”€â”€ Context Enrichment (Pre-Guidance)                 â”‚
â”‚  â”œâ”€â”€ Retrieval Strategies                              â”‚
â”‚  â””â”€â”€ Learning Extraction (Post-Guidance)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Primary: ChromaDB   â”‚      â”‚  Fallback: SQLite    â”‚
â”‚  â€¢ Semantic Search   â”‚â—„â”€â”€â”€â”€â–ºâ”‚  â€¢ User Profiles     â”‚
â”‚  â€¢ 3 Collections     â”‚ Auto â”‚  â€¢ Session History   â”‚
â”‚  â€¢ 96x Faster        â”‚ Fail â”‚  â€¢ Skill Progress    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ over â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®¾è®¡å“²å­¦

**ä»V2.0çš„"æ— çŠ¶æ€ä¸“å®¶"åˆ°V2.1çš„"æœ‰è®°å¿†å¯¼å¸ˆ"**

| V2.0 | V2.1 |
|------|------|
| æ¯æ¬¡å¯¹è¯ç‹¬ç«‹ | è·¨ä¼šè¯è¿ç»­å­¦ä¹  |
| åŸºäºè§„åˆ™å†³ç­– | åŸºäºå†å²ç»éªŒå†³ç­– |
| é™æ€çŸ¥è¯†åº“ | åŠ¨æ€æˆé•¿çŸ¥è¯†åº“ |
| æ— ä¸ªæ€§åŒ– | æ·±åº¦ä¸ªæ€§åŒ–æŒ‡å¯¼ |

---

## ç³»ç»Ÿåˆå§‹åŒ–

### é¦–æ¬¡å¯åŠ¨æµç¨‹

```python
# Pseudo-code: Memory System Initialization

def initialize_memory_system():
    """
    ACS-Mentorå¯åŠ¨æ—¶çš„å†…å­˜ç³»ç»Ÿåˆå§‹åŒ–
    åº”è¯¥åœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨ç³»ç»Ÿæ—¶è°ƒç”¨
    """

    # Step 1: åˆ›å»ºç›®å½•ç»“æ„
    create_directory(".acs_mentor/vector_db")
    create_directory(".acs_mentor/")

    # Step 2: åˆå§‹åŒ–SQLiteæ•°æ®åº“
    sqlite_conn = connect_sqlite(".acs_mentor/memory.db")
    execute_sql(sqlite_conn, memory_system.fallback_store.initialization_sql)

    # åˆ›å»ºæ‰€æœ‰è¡¨
    for table_name, table_def in memory_system.fallback_store.tables.items():
        execute_sql(sqlite_conn, table_def.schema)
        for index_sql in table_def.indexes:
            execute_sql(sqlite_conn, index_sql)

    # Step 3: åˆå§‹åŒ–ChromaDB
    try:
        chroma_client = chromadb.PersistentClient(
            path=".acs_mentor/vector_db"
        )

        # åˆ›å»º3ä¸ªcollections
        create_collection(
            chroma_client,
            name="user_interactions",
            metadata={"hnsw:space": "cosine"}
        )

        create_collection(
            chroma_client,
            name="guidance_cases",
            metadata={"hnsw:space": "cosine"}
        )

        create_collection(
            chroma_client,
            name="error_patterns",
            metadata={"hnsw:space": "cosine"}
        )

        log("ChromaDB initialized successfully")

    except Exception as e:
        log(f"ChromaDB initialization failed: {e}")
        log("System will use SQLite-only mode")

    # Step 4: å¥åº·æ£€æŸ¥
    health_status = {
        "chromadb": check_chromadb_health(),
        "sqlite": check_sqlite_health()
    }

    log(f"Memory system initialized: {health_status}")

    return health_status
```

### ä»V2.0è¿ç§»

```python
def migrate_from_v2_0():
    """
    å°†V2.0çš„user_capability_profileè¿ç§»åˆ°V2.1å†…å­˜ç³»ç»Ÿ
    """

    # Step 1: è¯»å–V2.0é…ç½®
    v2_profile = load_yaml("mentorship_goals.yaml").user_capability_profile

    # Step 2: è½¬æ¢ä¸ºV2.1æ ¼å¼
    v2_1_profile = {
        "user_id": generate_user_id(),  # é¦–æ¬¡ä½¿ç”¨æ—¶ç”Ÿæˆ
        "overall_level": v2_profile.user_level,
        "skill_study_design": v2_profile.skill_scores.study_design,
        "skill_statistics": v2_profile.skill_scores.statistical_methods,
        "skill_writing": v2_profile.skill_scores.scientific_writing,
        "skill_critical_appraisal": v2_profile.skill_scores.critical_appraisal,
        "current_learning_focus": v2_profile.current_focus_areas[0] if v2_profile.current_focus_areas else None,
        "skill_tree_progress": json.dumps(v2_profile.skill_tree)
    }

    # Step 3: æ’å…¥åˆ°SQLite
    insert_into_table("user_profiles", v2_1_profile)

    # Step 4: è¿ç§»å†å²é”™è¯¯è®°å½•ï¼ˆå¦‚æœæœ‰ï¼‰
    if v2_profile.error_history:
        for error in v2_profile.error_history:
            error_record = {
                "user_id": v2_1_profile["user_id"],
                "error_type": error.type,
                "error_category": categorize_error(error.type),
                "error_severity": error.severity,
                "error_description": error.description,
                "detected_at": error.timestamp
            }
            insert_into_table("error_tracking", error_record)

            # åŒæ—¶æ·»åŠ åˆ°ChromaDB error_patterns
            add_to_chromadb(
                collection="error_patterns",
                document=error.description,
                metadata=error_record
            )

    log("Migration from V2.0 completed")
```

---

## æ ¸å¿ƒæ“ä½œæµç¨‹

### å®Œæ•´å¯¹è¯æµç¨‹ä¸­çš„å†…å­˜æ“ä½œ

```
ç”¨æˆ·æ¶ˆæ¯åˆ°è¾¾
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pre-Guidance Phase (ä¸Šä¸‹æ–‡å¢å¼º)      â”‚
â”‚ â”œâ”€â”€ Load user profile                â”‚
â”‚ â”œâ”€â”€ Retrieve recent interactions     â”‚
â”‚ â”œâ”€â”€ Check recurring errors          â”‚
â”‚ â””â”€â”€ Search similar success cases     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    [enriched_context]
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Guidance Generation Phase            â”‚
â”‚ (ç°æœ‰V2.0 decision_logic_v2)         â”‚
â”‚ â”œâ”€â”€ Calculate urgency (8 factors)   â”‚
â”‚ â”œâ”€â”€ Select mode (Critic/Mentor)     â”‚
â”‚ â””â”€â”€ Generate response                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    [guidance_response]
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Post-Guidance Phase (å­¦ä¹ æå–)       â”‚
â”‚ â”œâ”€â”€ Quality self-check               â”‚
â”‚ â”œâ”€â”€ Extract learning insights        â”‚
â”‚ â”œâ”€â”€ Update user profile              â”‚
â”‚ â””â”€â”€ Store as case (if high quality)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    è¿”å›ç»™ç”¨æˆ·
```

### æ“ä½œ1: åŠ è½½ç”¨æˆ·ç”»åƒ

```python
def load_user_profile(user_id):
    """
    ä»SQLiteåŠ è½½ç”¨æˆ·èƒ½åŠ›ç”»åƒ
    ä½¿ç”¨ç¼“å­˜ä»¥æé«˜æ€§èƒ½
    """

    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"user_profile:{user_id}"
    cached = get_from_cache(cache_key)
    if cached and not is_expired(cached, ttl=300):  # 5åˆ†é’ŸTTL
        return cached

    # ä»æ•°æ®åº“æŸ¥è¯¢
    profile = query_sql("""
        SELECT *
        FROM user_profiles
        WHERE user_id = ?
    """, [user_id])

    if not profile:
        # é¦–æ¬¡ä½¿ç”¨ï¼Œåˆ›å»ºæ–°profile
        profile = create_default_profile(user_id)
        insert_into_table("user_profiles", profile)

    # æ›´æ–°ç¼“å­˜
    set_cache(cache_key, profile, ttl=300)

    return profile
```

### æ“ä½œ2: è¯­ä¹‰æœç´¢ç›¸ä¼¼æ¡ˆä¾‹

```python
def semantic_search_similar_cases(user_message, user_profile, top_k=5):
    """
    ä½¿ç”¨ChromaDBè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
    å¤±è´¥æ—¶é™çº§åˆ°SQLiteå…³é”®è¯åŒ¹é…
    """

    try:
        # Primary: ChromaDBè¯­ä¹‰æœç´¢
        collection = get_chromadb_collection("guidance_cases")

        # ç”Ÿæˆquery embedding
        query_embedding = generate_embedding(user_message)

        # æ„å»ºmetadataè¿‡æ»¤å™¨
        filters = {
            "$and": [
                {"user_level": {"$eq": user_profile.overall_level}},
                {"effectiveness_score": {"$gte": 0.8}}  # åªæ£€ç´¢é«˜è´¨é‡æ¡ˆä¾‹
            ]
        }

        # æ‰§è¡Œæœç´¢
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=filters
        )

        # é‡æ–°æ’åº
        ranked_results = rerank_results(
            results,
            user_profile=user_profile,
            ranking_formula=memory_system.retrieval_strategies.semantic_search.result_ranking.formula
        )

        return ranked_results

    except ChromaDBException as e:
        log(f"ChromaDB search failed, falling back to SQLite: {e}")

        # Fallback: SQLiteå…³é”®è¯åŒ¹é…
        keywords = extract_keywords(user_message)

        similar_cases = query_sql("""
            SELECT session_id, user_message, guidance_response, effectiveness_score
            FROM session_history sh
            JOIN user_interactions ui ON sh.session_id = ui.session_id
            WHERE ui.user_level = ?
              AND ui.effectiveness_score >= 0.8
              AND (
                  ui.user_message LIKE ? OR
                  ui.user_message LIKE ? OR
                  ui.user_message LIKE ?
              )
            ORDER BY ui.effectiveness_score DESC
            LIMIT ?
        """, [
            user_profile.overall_level,
            f"%{keywords[0]}%",
            f"%{keywords[1]}%",
            f"%{keywords[2]}%",
            top_k
        ])

        return similar_cases
```

### æ“ä½œ3: æ£€æµ‹é‡å¤é”™è¯¯

```python
def detect_recurring_errors(user_id, lookback_days=30):
    """
    æ£€æµ‹ç”¨æˆ·åœ¨è¿‡å»Nå¤©å†…çš„é‡å¤é”™è¯¯æ¨¡å¼
    è§¦å‘æ·±åº¦æŒ‡å¯¼
    """

    recurring_errors = query_sql("""
        SELECT
            error_type,
            error_category,
            COUNT(*) as occurrence_count,
            MAX(detected_at) as last_occurrence,
            GROUP_CONCAT(error_description, '; ') as all_descriptions
        FROM error_tracking
        WHERE user_id = ?
          AND detected_at >= date('now', '-{} days')
        GROUP BY error_type
        HAVING occurrence_count >= 2
        ORDER BY occurrence_count DESC
    """.format(lookback_days), [user_id])

    if recurring_errors:
        log(f"Detected {len(recurring_errors)} recurring error patterns")

        # ä¸ºæ¯ä¸ªé‡å¤é”™è¯¯æ£€ç´¢æœ€ä½³çº æ­£ç­–ç•¥
        for error in recurring_errors:
            # ä»guidance_casesæœç´¢é’ˆå¯¹æ­¤ç±»é”™è¯¯çš„æˆåŠŸæ•™å­¦æ¡ˆä¾‹
            teaching_cases = semantic_search_by_error_type(
                error_type=error.error_type,
                min_effectiveness=0.85
            )

            error['recommended_strategies'] = teaching_cases

    return recurring_errors
```

---

## Pre-Guidanceå†…å­˜å¢å¼º

### å®Œæ•´å®ç°

```python
def pre_guidance_context_enrichment(user_message, user_id, session_id):
    """
    Pre-Guidanceé˜¶æ®µï¼šåŠ è½½æ‰€æœ‰ç›¸å…³ä¸Šä¸‹æ–‡
    è¿”å›enriched_contextä¾›decision_logicä½¿ç”¨

    å¯¹åº” memory_system.yaml::retrieval_strategies::context_enrichment
    """

    enriched_context = {}

    # Stage 1: Load user profile
    enriched_context['user_profile'] = load_user_profile(user_id)

    # Stage 2: Retrieve recent interactions
    enriched_context['recent_history'] = query_sql("""
        SELECT session_id, user_message, guidance_response, mode_used, user_satisfaction
        FROM user_interactions
        WHERE user_id = ?
        ORDER BY timestamp DESC
        LIMIT 5
    """, [user_id])

    # Stage 3: Identify current learning focus
    enriched_context['current_focus'] = query_sql("""
        SELECT skill_domain, skill_name, current_level
        FROM skill_progress
        WHERE user_id = ?
        ORDER BY advancement_date DESC
        LIMIT 1
    """, [user_id])

    # Stage 4: Check for recurring errors
    enriched_context['recurring_errors'] = detect_recurring_errors(user_id)

    # Stage 5: Semantic search for similar success cases
    enriched_context['similar_success_cases'] = semantic_search_similar_cases(
        user_message=user_message,
        user_profile=enriched_context['user_profile'],
        top_k=3
    )

    # Stage 6: Complexity assessment (ä¸ºPhase 3å‡†å¤‡)
    enriched_context['estimated_complexity'] = estimate_task_complexity(
        user_message=user_message,
        user_profile=enriched_context['user_profile']
    )

    log(f"Context enrichment completed for session {session_id}")

    return enriched_context
```

### åœ¨Decision Logicä¸­ä½¿ç”¨

```python
# åœ¨ decision_logic_v2_extension.md çš„å†³ç­–æµç¨‹ä¸­é›†æˆ

def calculate_urgency_v2_enhanced(user_message, user_id, session_id):
    """
    V2.1å¢å¼ºç‰ˆurgencyè®¡ç®—
    é›†æˆå†…å­˜ç³»ç»Ÿçš„ä¸Šä¸‹æ–‡
    """

    # ğŸ†• V2.1: Pre-Guidanceä¸Šä¸‹æ–‡å¢å¼º
    enriched_context = pre_guidance_context_enrichment(
        user_message, user_id, session_id
    )

    # åŸæœ‰çš„8-factoræ£€æµ‹
    factors = {
        'error_detection': detect_error(user_message),
        'goal_threatened': check_goal_threat(user_message),
        'expertise_match': calculate_expertise_match(user_message),
        'misrepresented': detect_misrepresentation(user_message),
        'silence_too_long': calculate_silence_duration(),
        'agenda_opportunity': detect_agenda_opportunity(user_message),
        'growth_opportunity': detect_growth_opportunity(user_message, enriched_context),  # ğŸ†• ä½¿ç”¨ä¸Šä¸‹æ–‡
        'strategic_insight': detect_strategic_moment(user_message, enriched_context)     # ğŸ†• ä½¿ç”¨ä¸Šä¸‹æ–‡
    }

    # ğŸ†• V2.1: æ ¹æ®é‡å¤é”™è¯¯è°ƒæ•´æƒé‡
    weights = get_decision_weights()
    if enriched_context['recurring_errors']:
        # å¦‚æœæ£€æµ‹åˆ°é‡å¤é”™è¯¯ï¼Œå¼ºåŒ–error_detectionå’Œgrowth_opportunityæƒé‡
        weights['error_detection'] *= 1.2
        weights['growth_opportunity'] *= 1.3
        log("Boosted weights due to recurring errors")

    # ğŸ†• V2.1: æ ¹æ®ç”¨æˆ·å†å²è°ƒæ•´æ¨¡å¼
    mode = select_mode_based_on_context(enriched_context)
    adjusted_weights = apply_mode_adjustments(weights, mode)

    # è®¡ç®—urgency
    urgency = calculate_weighted_sum(factors, adjusted_weights)

    return {
        'urgency': urgency,
        'factors': factors,
        'mode': mode,
        'enriched_context': enriched_context  # ä¼ é€’ç»™response generationä½¿ç”¨
    }
```

---

## Post-Guidanceå­¦ä¹ æå–

### å®Œæ•´å®ç°

```python
def post_guidance_learning_extraction(
    user_message,
    guidance_response,
    decision_result,
    user_id,
    session_id
):
    """
    Post-Guidanceé˜¶æ®µï¼šä»æœ¬æ¬¡äº¤äº’ä¸­å­¦ä¹ 
    æ›´æ–°å†…å­˜ç³»ç»Ÿ
    """

    learning_results = {}

    # Step 1: Quality Self-Check
    quality_score = evaluate_guidance_quality(
        guidance_response=guidance_response,
        decision_result=decision_result
    )
    learning_results['quality_score'] = quality_score

    if quality_score < 0.6:
        log(f"âš ï¸ Low quality guidance detected (score={quality_score})")
        # æœªæ¥å¯ä»¥è§¦å‘äººå·¥å®¡æ ¸

    # Step 2: Extract Learning Insights
    insights = extract_learning_insights(
        user_message=user_message,
        guidance_response=guidance_response,
        enriched_context=decision_result['enriched_context']
    )
    learning_results['insights'] = insights

    # Step 3: Update User Profile
    if insights['skill_advancement']:
        update_skill_progress(
            user_id=user_id,
            skill_domain=insights['skill_domain'],
            new_level=insights['new_level'],
            evidence=insights['advancement_evidence']
        )

    update_user_profile_stats(
        user_id=user_id,
        interaction_count=1,
        errors_detected=len(decision_result['factors']['error_detection']),
        guidance_provided=1
    )

    # Step 4: Store Interaction
    interaction_record = {
        "session_id": session_id,
        "user_id": user_id,
        "user_message": user_message,
        "guidance_response": guidance_response,
        "mode_used": decision_result['mode'],
        "complexity_score": decision_result['enriched_context']['estimated_complexity'],
        "quality_score": quality_score,
        "timestamp": now()
    }

    # å­˜å…¥SQLite
    insert_into_table("user_interactions", interaction_record)

    # å­˜å…¥ChromaDB (å¼‚æ­¥ï¼Œä¸é˜»å¡å“åº”)
    if quality_score >= 0.7:  # åªå­˜å‚¨ä¸­ç­‰è´¨é‡ä»¥ä¸Šçš„äº¤äº’
        add_to_chromadb_async(
            collection="user_interactions",
            document=user_message + " " + guidance_response,
            metadata=interaction_record
        )

    # Step 5: Store as Success Case (if exceptional)
    if quality_score >= 0.85:
        guidance_case = {
            "case_id": generate_case_id(),
            "problem_type": insights['problem_type'],
            "user_level": decision_result['enriched_context']['user_profile'].overall_level,
            "guidance_strategy": decision_result['mode'],
            "effectiveness_score": quality_score,
            "user_message": user_message,
            "guidance_template": extract_template(guidance_response)
        }

        add_to_chromadb(
            collection="guidance_cases",
            document=guidance_response,
            metadata=guidance_case
        )

        log(f"âœ¨ Stored as high-quality guidance case (score={quality_score})")

    # Step 6: Pattern Learning (ä¸ºV2.5 Neural Learningå‡†å¤‡)
    store_pattern_triple(
        problem_type=insights['problem_type'],
        strategy=decision_result['mode'],
        effectiveness=quality_score
    )

    learning_results['stored'] = True

    return learning_results
```

### Quality Self-Checkå®ç°

```python
def evaluate_guidance_quality(guidance_response, decision_result):
    """
    è‡ªåŠ¨è¯„ä¼°guidanceè´¨é‡
    å¯¹åº” CLAUDE_FLOW_INSIGHTS.md::Phase 2::quality_check
    """

    score = 1.0
    checks = []

    # Check 1: æ˜¯å¦å¼•ç”¨äº†å…·ä½“æ ‡å‡†/æ–‡çŒ®?
    has_references = check_for_references(guidance_response)
    if not has_references:
        score -= 0.15
        checks.append("missing_references")

    # Check 2: æ˜¯å¦æä¾›äº†å¯æ“ä½œå»ºè®®?
    has_actionable_advice = check_for_actionable_items(guidance_response)
    if not has_actionable_advice:
        score -= 0.20
        checks.append("missing_actionable_advice")

    # Check 3: æ˜¯å¦åŒ¹é…ç”¨æˆ·èƒ½åŠ›æ°´å¹³?
    user_level = decision_result['enriched_context']['user_profile'].overall_level
    complexity_match = check_complexity_match(guidance_response, user_level)
    if not complexity_match:
        score -= 0.15
        checks.append("complexity_mismatch")

    # Check 4: æ˜¯å¦å›ç­”äº†ç”¨æˆ·çš„å®é™…é—®é¢˜?
    relevance_score = calculate_relevance(
        user_message=decision_result['user_message'],
        guidance_response=guidance_response
    )
    if relevance_score < 0.7:
        score -= 0.20
        checks.append("low_relevance")

    # Check 5: è¯­è¨€æ˜¯å¦professionalä¸”constructive?
    tone_check = analyze_tone(guidance_response)
    if tone_check != "professional_constructive":
        score -= 0.10
        checks.append("tone_issue")

    final_score = max(score, 0.0)

    log(f"Quality check: score={final_score}, issues={checks}")

    return final_score
```

---

## é”™è¯¯æ¨¡å¼æ£€æµ‹

### å®Œæ•´å·¥ä½œæµ

```python
def handle_error_detection_with_memory(user_message, user_id, error_detected):
    """
    ç»“åˆå†…å­˜ç³»ç»Ÿçš„é”™è¯¯å¤„ç†æµç¨‹
    æ£€æµ‹æ˜¯å¦ä¸ºé‡å¤é”™è¯¯ï¼Œå¹¶ç›¸åº”è°ƒæ•´æŒ‡å¯¼ç­–ç•¥
    """

    if not error_detected:
        return None

    # Step 1: è®°å½•æœ¬æ¬¡é”™è¯¯
    error_record = {
        "user_id": user_id,
        "error_type": error_detected['type'],
        "error_category": error_detected['category'],
        "error_severity": error_detected['severity'],
        "error_description": error_detected['description'],
        "detected_at": now()
    }

    insert_into_table("error_tracking", error_record)

    # Step 2: æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤é”™è¯¯
    recurrence_check = query_sql("""
        SELECT COUNT(*) as count
        FROM error_tracking
        WHERE user_id = ?
          AND error_type = ?
          AND detected_at >= date('now', '-30 days')
    """, [user_id, error_detected['type']])

    is_recurring = recurrence_check['count'] >= 2

    if is_recurring:
        log(f"ğŸ” Recurring error detected: {error_detected['type']} ({recurrence_check['count']} times)")

        # Step 3: æ£€ç´¢é’ˆå¯¹æ­¤é‡å¤é”™è¯¯çš„æœ€ä½³æ•™å­¦ç­–ç•¥
        teaching_strategies = semantic_search_by_error_type(
            error_type=error_detected['type'],
            search_collection="guidance_cases",
            filter_tags=["deep_teaching", "concept_framework"]
        )

        # Step 4: å‡çº§åˆ°Deep Mentorshipæ¨¡å¼
        return {
            "error": error_detected,
            "is_recurring": True,
            "occurrence_count": recurrence_check['count'],
            "recommended_mode": "deep_mentorship",
            "teaching_strategies": teaching_strategies,
            "intervention_level": "high"
        }

    else:
        # é¦–æ¬¡é”™è¯¯ï¼Œæ ‡å‡†çº æ­£
        return {
            "error": error_detected,
            "is_recurring": False,
            "occurrence_count": 1,
            "recommended_mode": "standard_critic",
            "intervention_level": "moderate"
        }
```

### å­˜å‚¨åˆ°Error Patterns Collection

```python
def store_error_pattern(error_record, correction_strategy, effectiveness):
    """
    å°†é”™è¯¯åŠå…¶çº æ­£ç­–ç•¥å­˜å…¥error_patterns collection
    ç”¨äºæœªæ¥ç›¸ä¼¼é”™è¯¯çš„å¿«é€Ÿæ£€ç´¢
    """

    pattern_document = f"""
    Error Type: {error_record['error_type']}
    Category: {error_record['error_category']}
    Description: {error_record['error_description']}

    Correction Strategy:
    {correction_strategy}

    Effectiveness: {effectiveness}
    """

    metadata = {
        "error_type": error_record['error_type'],
        "error_category": error_record['error_category'],
        "error_severity": error_record['error_severity'],
        "correction_strategy": correction_strategy,
        "effectiveness_score": effectiveness,
        "created_at": now()
    }

    add_to_chromadb(
        collection="error_patterns",
        document=pattern_document,
        metadata=metadata
    )
```

---

## ç”¨æˆ·èƒ½åŠ›è¿½è¸ª

### æŠ€èƒ½è¿›å±•æ£€æµ‹

```python
def check_skill_advancement(user_id, session_id, enriched_context):
    """
    æ£€æµ‹ç”¨æˆ·åœ¨æœ¬æ¬¡å¯¹è¯ä¸­æ˜¯å¦å±•ç¤ºäº†æŠ€èƒ½æå‡
    å¯¹åº” mentorship_goals.yaml::skill_domains::mastery_criteria
    """

    # è·å–ç”¨æˆ·å½“å‰æŠ€èƒ½è¯„åˆ†
    current_skills = enriched_context['user_profile']

    # åˆ†ææœ¬æ¬¡å¯¹è¯ä¸­ç”¨æˆ·çš„è¡¨ç°
    performance_indicators = {
        "study_design": analyze_study_design_understanding(session_id),
        "statistics": analyze_statistical_understanding(session_id),
        "writing": analyze_writing_quality(session_id),
        "critical_appraisal": analyze_critical_thinking(session_id)
    }

    advancements = []

    for domain, performance in performance_indicators.items():
        current_level = getattr(current_skills, f"skill_{domain}")

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ™‹çº§æ ‡å‡†
        if check_mastery_criteria(domain, current_level, performance):
            new_level = get_next_level(current_level)

            # è®°å½•æ™‹çº§
            advancement = {
                "user_id": user_id,
                "skill_domain": domain,
                "previous_level": level_to_string(current_level),
                "current_level": level_to_string(new_level),
                "mastery_evidence": performance['evidence'],
                "advancement_date": now()
            }

            insert_into_table("skill_progress", advancement)

            # æ›´æ–°user_profile
            update_sql(f"""
                UPDATE user_profiles
                SET skill_{domain} = ?,
                    updated_at = CURRENT_TIMESTAMP
                WHERE user_id = ?
            """, [new_level, user_id])

            advancements.append(advancement)

            log(f"ğŸ“ Skill advancement: {domain} {level_to_string(current_level)} â†’ {level_to_string(new_level)}")

    return advancements
```

### å­¦ä¹ è½¨è¿¹å¯è§†åŒ–

```python
def get_learning_trajectory(user_id, time_window_days=90):
    """
    è·å–ç”¨æˆ·çš„å­¦ä¹ è½¨è¿¹
    ç”¨äºå‘ç”¨æˆ·å±•ç¤ºæˆé•¿è¿›åº¦
    """

    trajectory = {
        "user_id": user_id,
        "time_window": time_window_days,
        "skill_advancements": [],
        "interaction_stats": {},
        "error_rate_trend": []
    }

    # 1. æŠ€èƒ½æ™‹çº§å†å²
    trajectory['skill_advancements'] = query_sql("""
        SELECT skill_domain, previous_level, current_level, advancement_date, mastery_evidence
        FROM skill_progress
        WHERE user_id = ?
          AND advancement_date >= date('now', '-{} days')
        ORDER BY advancement_date ASC
    """.format(time_window_days), [user_id])

    # 2. äº¤äº’ç»Ÿè®¡
    trajectory['interaction_stats'] = query_sql("""
        SELECT
            COUNT(*) as total_sessions,
            AVG(complexity_score) as avg_complexity,
            AVG(quality_score) as avg_quality
        FROM session_history
        WHERE user_id = ?
          AND start_time >= date('now', '-{} days')
    """.format(time_window_days), [user_id])[0]

    # 3. é”™è¯¯ç‡è¶‹åŠ¿ (æŒ‰å‘¨ç»Ÿè®¡)
    trajectory['error_rate_trend'] = query_sql("""
        SELECT
            strftime('%Y-W%W', detected_at) as week,
            COUNT(*) as error_count
        FROM error_tracking
        WHERE user_id = ?
          AND detected_at >= date('now', '-{} days')
        GROUP BY week
        ORDER BY week ASC
    """.format(time_window_days), [user_id])

    return trajectory
```

---

## é™çº§ä¸å®¹é”™

### å¥åº·æ£€æŸ¥

```python
def check_memory_system_health():
    """
    å®šæœŸæ£€æŸ¥å†…å­˜ç³»ç»Ÿå¥åº·çŠ¶æ€
    æŒ‰ memory_system.yaml::fault_tolerance::health_checks é…ç½®
    """

    health_status = {
        "chromadb": "unknown",
        "sqlite": "unknown",
        "overall": "unknown"
    }

    # Check ChromaDB
    try:
        chroma_client = get_chromadb_client()
        chroma_client.heartbeat()  # Ping
        health_status["chromadb"] = "healthy"
    except Exception as e:
        log(f"ChromaDB health check failed: {e}")
        health_status["chromadb"] = "unhealthy"

    # Check SQLite
    try:
        sqlite_conn = get_sqlite_connection()
        result = execute_sql(sqlite_conn, "SELECT 1;")
        if result:
            health_status["sqlite"] = "healthy"
        else:
            health_status["sqlite"] = "unhealthy"
    except Exception as e:
        log(f"SQLite health check failed: {e}")
        health_status["sqlite"] = "unhealthy"

    # Overall status
    if health_status["chromadb"] == "healthy" and health_status["sqlite"] == "healthy":
        health_status["overall"] = "optimal"
    elif health_status["sqlite"] == "healthy":
        health_status["overall"] = "degraded"  # ChromaDBå¤±è´¥ï¼Œä½†SQLiteæ­£å¸¸
    else:
        health_status["overall"] = "critical"  # SQLiteä¹Ÿå¤±è´¥

    return health_status
```

### è‡ªåŠ¨é™çº§é€»è¾‘

```python
def execute_retrieval_with_fallback(query_type, **params):
    """
    å¸¦è‡ªåŠ¨é™çº§çš„æ£€ç´¢æ“ä½œ
    ä¼˜å…ˆä½¿ç”¨ChromaDBï¼Œå¤±è´¥æ—¶é™çº§åˆ°SQLite
    """

    health = check_memory_system_health()

    if health["chromadb"] == "healthy":
        # Primary: ä½¿ç”¨ChromaDBè¯­ä¹‰æœç´¢
        try:
            return chromadb_retrieval(query_type, **params)
        except Exception as e:
            log(f"ChromaDB retrieval failed, falling back: {e}")
            # ç»§ç»­åˆ°fallback

    if health["sqlite"] == "healthy":
        # Fallback: ä½¿ç”¨SQLiteç²¾ç¡®åŒ¹é…
        log("Using SQLite fallback mode")
        return sqlite_retrieval(query_type, **params)

    # Both failed
    log("âš ï¸ Both ChromaDB and SQLite unavailable, using stateless mode")
    return None  # ç³»ç»Ÿå°†ä»¥V2.0æ— å†…å­˜æ¨¡å¼è¿è¡Œ
```

---

## å®ç°å‚è€ƒ

### Pythonä¾èµ–

```python
# requirements.txt for V2.1 Memory System

chromadb>=0.4.0              # è¯­ä¹‰å‘é‡æ•°æ®åº“
sentence-transformers>=2.2.0  # æœ¬åœ°embeddingæ¨¡å‹ (all-MiniLM-L6-v2)
sqlite3                       # å†…ç½®äºPython
numpy>=1.24.0
```

### å®Œæ•´é›†æˆç¤ºä¾‹

```python
# main_workflow_v2_1.py
# ACS-Mentor V2.1å®Œæ•´å·¥ä½œæµç¤ºä¾‹

def handle_user_message_v2_1(user_message, user_id, session_id):
    """
    V2.1å®Œæ•´å·¥ä½œæµï¼šPre â†’ Decision â†’ Post
    """

    # ========== Pre-Guidance Phase ==========
    enriched_context = pre_guidance_context_enrichment(
        user_message=user_message,
        user_id=user_id,
        session_id=session_id
    )

    log(f"âœ“ Context enriched: {len(enriched_context['similar_success_cases'])} similar cases found")

    # ========== Decision & Generation Phase ==========
    decision_result = calculate_urgency_v2_enhanced(
        user_message=user_message,
        user_id=user_id,
        session_id=session_id
    )

    # ç”Ÿæˆå“åº” (ä½¿ç”¨enriched_contextå’Œsimilar_casesä½œä¸ºæ¨¡æ¿)
    guidance_response = generate_guidance_response(
        user_message=user_message,
        decision_result=decision_result,
        template_cases=enriched_context['similar_success_cases']
    )

    log(f"âœ“ Guidance generated: mode={decision_result['mode']}, urgency={decision_result['urgency']}")

    # ========== Post-Guidance Phase ==========
    learning_results = post_guidance_learning_extraction(
        user_message=user_message,
        guidance_response=guidance_response,
        decision_result=decision_result,
        user_id=user_id,
        session_id=session_id
    )

    log(f"âœ“ Learning extracted: quality={learning_results['quality_score']}")

    # æ£€æŸ¥æŠ€èƒ½æ™‹çº§
    advancements = check_skill_advancement(user_id, session_id, enriched_context)
    if advancements:
        for adv in advancements:
            log(f"ğŸ“ Skill up: {adv['skill_domain']} â†’ {adv['current_level']}")
            # å¯ä»¥åœ¨å“åº”ä¸­æ·»åŠ ç¥è´ºä¿¡æ¯
            guidance_response += f"\n\nğŸ‰ æ­å–œï¼æ‚¨åœ¨ {adv['skill_domain']} æ–¹é¢å·²æ™‹çº§åˆ° {adv['current_level']} æ°´å¹³ï¼"

    return guidance_response
```

---

## æ€»ç»“

### V2.1å†…å­˜ç³»ç»Ÿçš„æ ¸å¿ƒä»·å€¼

1. **è·¨ä¼šè¯å­¦ä¹ ** - ä»"å¥å¿˜ä¸“å®¶"åˆ°"æœ‰è®°å¿†å¯¼å¸ˆ"
2. **ä¸ªæ€§åŒ–æŒ‡å¯¼** - åŸºäºç”¨æˆ·å†å²è°ƒæ•´å“åº”æ·±åº¦å’Œæ¨¡å¼
3. **é‡å¤é”™è¯¯æ£€æµ‹** - è¯†åˆ«å­¦ä¹ éšœç¢ï¼Œè§¦å‘æ·±åº¦æ•™å­¦
4. **æœ€ä½³å®è·µå¤ç”¨** - ä»å†å²æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹ æ¨¡æ¿
5. **èƒ½åŠ›è¿½è¸ªå¯è§†åŒ–** - è®©ç”¨æˆ·çœ‹åˆ°è‡ªå·±çš„æˆé•¿è½¨è¿¹

### ä¸Claude-Flowçš„å¯¹æ ‡

| åŠŸèƒ½ | Claude-Flow | ACS-Mentor V2.1 |
|------|-------------|-----------------|
| è¯­ä¹‰æœç´¢ | âœ… AgentDB (96xåŠ é€Ÿ) | âœ… ChromaDB (ç±»ä¼¼æ€§èƒ½) |
| æŒä¹…åŒ–å­˜å‚¨ | âœ… SQLite | âœ… SQLite (4è¡¨) |
| è‡ªåŠ¨é™çº§ | âœ… Hybrid fallback | âœ… ChromaDBâ†’SQLiteâ†’Stateless |
| Pattern learning | âœ… Neural training | ğŸ”„ V2.5è®¡åˆ’ |
| è·¨ä¼šè¯æ¢å¤ | âœ… Hive-Mind | âœ… User profile + Session history |

### ä¸‹ä¸€æ­¥ï¼ˆPhase 2ï¼‰

ç»§ç»­å®æ–½Pre/Post Hooksçš„decision_logicé›†æˆï¼Œå°†æœ¬æŒ‡å—ä¸­çš„æ“ä½œåµŒå…¥åˆ°V2.0çš„å†³ç­–æµç¨‹ä¸­ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-11-16
**ä½œè€…**: ACS-Mentor V2.1 Development Team
